Search.setIndex({"docnames": ["index", "quickstart", "stubs/ddql_optimal_execution.agent.DDQL", "stubs/ddql_optimal_execution.agent.TWAP", "stubs/ddql_optimal_execution.environnement.MarketEnvironnement", "stubs/ddql_optimal_execution.experience_replay.ExperienceReplay", "stubs/ddql_optimal_execution.state.State", "stubs/ddql_optimal_execution.state.StateArray", "usage"], "filenames": ["index.rst", "quickstart.rst", "stubs/ddql_optimal_execution.agent.DDQL.rst", "stubs/ddql_optimal_execution.agent.TWAP.rst", "stubs/ddql_optimal_execution.environnement.MarketEnvironnement.rst", "stubs/ddql_optimal_execution.experience_replay.ExperienceReplay.rst", "stubs/ddql_optimal_execution.state.State.rst", "stubs/ddql_optimal_execution.state.StateArray.rst", "usage.rst"], "titles": ["Welcome to DDQL Optimal Execution\u2019s documentation!", "Quickstart Guide", "ddql_optimal_execution.agent.DDQL", "ddql_optimal_execution.agent.TWAP", "ddql_optimal_execution.environnement.MarketEnvironnement", "ddql_optimal_execution.experience_replay.ExperienceReplay", "ddql_optimal_execution.state.State", "ddql_optimal_execution.state.StateArray", "Installation"], "terms": {"instal": 0, "quickstart": 0, "guid": 0, "from": [1, 4, 5], "ddql_optimal_execut": 1, "import": 1, "ddql": [1, 8], "marketenvironn": 1, "experiencereplai": 1, "twap": 1, "creat": 1, "environn": 1, "env": 1, "initial_inventori": [1, 4], "500": 1, "multi_episod": [1, 4], "true": [1, 4], "agent": [1, 4, 5], "state_s": [1, 2], "initial_budget": [1, 2, 3], "horizon": [1, 2, 3, 5], "experi": [1, 2, 5], "replai": [1, 5], "store": [1, 5], "exp_replai": 1, "capac": [1, 5], "1000": 1, "train": [1, 2, 5], "everi": 1, "detect": 1, "episod": [1, 4, 5], "rang": 1, "len": 1, "historical_data_seri": 1, "swap_episod": [1, 4], "while": 1, "done": [1, 2, 5], "current_st": 1, "get_stat": [1, 4], "action": [1, 2, 3, 4, 5], "reward": [1, 2, 4, 5], "step": [1, 3, 4, 5], "distance2horizon": 1, "state": [1, 2, 3, 4, 5], "period": [1, 2, 4], "push": [1, 5], "copi": [1, 4, 6], "1": [1, 2], "els": 1, "2": 1, "learn": [1, 2, 5], "sampl": [1, 5], "128": [1, 5], "class": [2, 3, 4, 5, 6, 7], "state_dict": 2, "dict": 2, "none": [2, 4, 5, 7], "greedy_decay_r": 2, "float": [2, 4, 5], "0": [2, 4], "95": 2, "target_update_r": 2, "int": [2, 3, 4, 5], "15": 2, "initial_greedi": 2, "mode": 2, "str": [2, 4], "lr": 2, "001": 2, "5": [2, 4], "100": [2, 3, 4], "gamma": 2, "99": 2, "quadratic_penalty_coeffici": [2, 4], "01": [2, 4], "sourc": [2, 3, 4, 5, 6, 7, 8], "__init__": [2, 3, 4, 5, 6, 7], "method": [2, 3, 4, 5, 6, 7], "__complete_target": 2, "experience_batch": 2, "ndarrai": 2, "tupl": [2, 5], "torch": 2, "tensor": 2, "The": [2, 3, 4, 5, 8], "function": [2, 3, 4, 5], "take": [2, 3, 5], "batch": [2, 5], "return": [2, 3, 4, 5], "correspond": 2, "target": 2, "reinforc": [2, 5], "paramet": [2, 3, 4, 5], "np": 2, "A": [2, 4], "where": [2, 5], "each": [2, 4, 5], "i": [2, 3, 4, 5, 8], "dictionari": 2, "contain": [2, 3], "inform": [2, 3], "about": [2, 3, 4], "singl": 2, "transit": [2, 5], "environ": [2, 3, 4, 5], "kei": 2, "next_stat": [2, 5], "type": [2, 4, 5], "three": 2, "__get_act": [2, 3], "thi": [2, 3, 4, 5], "either": 2, "random": [2, 5], "binomi": 2, "distribut": 2, "index": 2, "maximum": [2, 5], "valu": [2, 3, 4, 5], "output": 2, "neural": 2, "network": 2, "depend": 2, "certain": [2, 4], "condit": 2, "an": [2, 3, 4, 5], "instanc": [2, 3], "which": [2, 3, 4, 5], "current": [2, 3, 4, 5], "oper": [2, 3], "repres": [2, 3, 4, 5], "taken": [2, 4, 5], "base": [2, 3, 4], "given": [2, 4, 5], "If": [2, 4], "greedi": 2, "set": [2, 4], "gener": 2, "us": [2, 5], "": [2, 3], "inventori": [2, 4], "number": [2, 4, 5], "trial": 2, "probabl": 2, "success": 2, "otherwis": [2, 4], "determin": [2, 4, 5], "main": 2, "__update_target_net": 2, "updat": [2, 4, 5], "load": 2, "eval": 2, "put": 2, "evalu": 2, "numpi": 2, "arrai": [2, 5], "budget": 3, "It": [3, 5], "time": [3, 4], "posit": [3, 5], "ani": 3, "other": 3, "relev": 3, "integ": [3, 4], "result": 3, "divis": 3, "attribut": [3, 6, 7], "object": [3, 4, 5], "data_path": 4, "data": 4, "n_period": 4, "bool": 4, "fals": 4, "__compute_reward": 4, "comput": 4, "histor": 4, "price": 4, "input": 4, "share": 4, "sell": 4, "calcul": 4, "__update_st": 4, "manag": 4, "amount": 4, "subtract": 4, "level": 4, "self": 4, "itself": 4, "boolean": 4, "whether": 4, "should": 4, "origin": 4, "option": [4, 5], "reset": 4, "reiniti": 4, "its": 4, "initi": 4, "execut": [4, 8], "one": [4, 5], "within": 4, "rais": 4, "error": 4, "invalid": 4, "In": [4, 5], "case": [4, 5], "assum": 4, "make": 4, "decis": 4, "how": [4, 5], "much": 4, "item": 4, "quantiti": 4, "obtain": 4, "after": [4, 5], "swap": 4, "seri": 4, "accordingli": 4, "10000": 5, "__make_room": 5, "randomli": 5, "delet": 5, "row": 5, "memori": 5, "list": 5, "first": 5, "half": 5, "shift": 5, "remain": 5, "up": 5, "get_sampl": 5, "batch_siz": 5, "specifi": 5, "size": 5, "select": 5, "buffer": 5, "infer": 5, "mean": 5, "dist2horizon": 5, "add": 5, "fix": 5, "usual": 5, "vector": 5, "describ": 5, "receiv": 5, "q": 5, "pair": 5, "algorithm": 5, "next": 5, "refer": 5, "distanc": 5, "can": [5, 8], "befor": 5, "end": 5, "keep": 5, "track": 5, "mani": 5, "ar": 5, "left": 5, "when": 5, "arg": [6, 7], "kwarg": 6, "properti": [6, 7], "astensor": [6, 7], "shallow": 6, "d": 6, "update_st": 6, "append": 7, "optim": 8, "code": 8, "avail": 8, "github": 8, "you": 8, "clone": 8, "repositori": 8, "follow": 8, "command": 8, "git": 8, "http": 8, "com": 8, "g0bel1n": 8, "cd": 8, "pip": 8, "r": 8, "requir": 8, "txt": 8}, "objects": {"ddql_optimal_execution.agent": [[2, 0, 1, "", "DDQL"], [3, 0, 1, "", "TWAP"]], "ddql_optimal_execution.agent.DDQL": [[2, 1, 1, "", "__complete_target"], [2, 1, 1, "", "__get_action"], [2, 1, 1, "", "__init__"], [2, 1, 1, "", "__update_target_net"], [2, 1, 1, "", "eval"], [2, 1, 1, "", "learn"], [2, 1, 1, "", "train"]], "ddql_optimal_execution.agent.TWAP": [[3, 1, 1, "", "__get_action"], [3, 1, 1, "", "__init__"]], "ddql_optimal_execution.environnement": [[4, 0, 1, "", "MarketEnvironnement"]], "ddql_optimal_execution.environnement.MarketEnvironnement": [[4, 1, 1, "", "__compute_reward"], [4, 1, 1, "", "__init__"], [4, 1, 1, "", "__update_state"], [4, 1, 1, "", "get_state"], [4, 1, 1, "", "reset"], [4, 1, 1, "", "step"], [4, 1, 1, "", "swap_episode"]], "ddql_optimal_execution.experience_replay": [[5, 0, 1, "", "ExperienceReplay"]], "ddql_optimal_execution.experience_replay.ExperienceReplay": [[5, 1, 1, "", "__init__"], [5, 1, 1, "", "__make_room"], [5, 1, 1, "", "get_sample"], [5, 1, 1, "", "push"]], "ddql_optimal_execution.state": [[6, 0, 1, "", "State"], [7, 0, 1, "", "StateArray"]], "ddql_optimal_execution.state.State": [[6, 1, 1, "", "__init__"], [6, 2, 1, "", "astensor"], [6, 1, 1, "", "copy"], [6, 1, 1, "", "update_state"]], "ddql_optimal_execution.state.StateArray": [[7, 1, 1, "", "__init__"], [7, 1, 1, "", "append"], [7, 2, 1, "", "astensor"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"]}, "titleterms": {"welcom": 0, "ddql": [0, 2], "optim": 0, "execut": 0, "": 0, "document": 0, "content": 0, "main": 0, "object": 0, "quickstart": 1, "guid": 1, "ddql_optimal_execut": [2, 3, 4, 5, 6, 7], "agent": [2, 3], "twap": 3, "environn": 4, "marketenvironn": 4, "experience_replai": 5, "experiencereplai": 5, "state": [6, 7], "statearrai": 7, "instal": 8}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Welcome to DDQL Optimal Execution\u2019s documentation!": [[0, "welcome-to-ddql-optimal-execution-s-documentation"]], "Contents:": [[0, null]], "Main Objects": [[0, "main-objects"]], "Quickstart Guide": [[1, "quickstart-guide"]], "ddql_optimal_execution.agent.DDQL": [[2, "ddql-optimal-execution-agent-ddql"]], "ddql_optimal_execution.agent.TWAP": [[3, "ddql-optimal-execution-agent-twap"]], "ddql_optimal_execution.environnement.MarketEnvironnement": [[4, "ddql-optimal-execution-environnement-marketenvironnement"]], "ddql_optimal_execution.experience_replay.ExperienceReplay": [[5, "ddql-optimal-execution-experience-replay-experiencereplay"]], "ddql_optimal_execution.state.State": [[6, "ddql-optimal-execution-state-state"]], "ddql_optimal_execution.state.StateArray": [[7, "ddql-optimal-execution-state-statearray"]], "Installation": [[8, "installation"]]}, "indexentries": {"ddql (class in ddql_optimal_execution.agent)": [[2, "ddql_optimal_execution.agent.DDQL"]], "__complete_target() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.__complete_target"]], "__get_action() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.__get_action"]], "__init__() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.__init__"]], "__update_target_net() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.__update_target_net"]], "eval() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.eval"]], "learn() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.learn"]], "train() (ddql_optimal_execution.agent.ddql method)": [[2, "ddql_optimal_execution.agent.DDQL.train"]], "twap (class in ddql_optimal_execution.agent)": [[3, "ddql_optimal_execution.agent.TWAP"]], "__get_action() (ddql_optimal_execution.agent.twap method)": [[3, "ddql_optimal_execution.agent.TWAP.__get_action"]], "__init__() (ddql_optimal_execution.agent.twap method)": [[3, "ddql_optimal_execution.agent.TWAP.__init__"]], "marketenvironnement (class in ddql_optimal_execution.environnement)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement"]], "__compute_reward() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.__compute_reward"]], "__init__() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.__init__"]], "__update_state() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.__update_state"]], "get_state() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.get_state"]], "reset() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.reset"]], "step() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.step"]], "swap_episode() (ddql_optimal_execution.environnement.marketenvironnement method)": [[4, "ddql_optimal_execution.environnement.MarketEnvironnement.swap_episode"]], "experiencereplay (class in ddql_optimal_execution.experience_replay)": [[5, "ddql_optimal_execution.experience_replay.ExperienceReplay"]], "__init__() (ddql_optimal_execution.experience_replay.experiencereplay method)": [[5, "ddql_optimal_execution.experience_replay.ExperienceReplay.__init__"]], "__make_room() (ddql_optimal_execution.experience_replay.experiencereplay method)": [[5, "ddql_optimal_execution.experience_replay.ExperienceReplay.__make_room"]], "get_sample() (ddql_optimal_execution.experience_replay.experiencereplay method)": [[5, "ddql_optimal_execution.experience_replay.ExperienceReplay.get_sample"]], "push() (ddql_optimal_execution.experience_replay.experiencereplay method)": [[5, "ddql_optimal_execution.experience_replay.ExperienceReplay.push"]], "state (class in ddql_optimal_execution.state)": [[6, "ddql_optimal_execution.state.State"]], "__init__() (ddql_optimal_execution.state.state method)": [[6, "ddql_optimal_execution.state.State.__init__"]], "astensor (ddql_optimal_execution.state.state property)": [[6, "ddql_optimal_execution.state.State.astensor"]], "copy() (ddql_optimal_execution.state.state method)": [[6, "ddql_optimal_execution.state.State.copy"]], "update_state() (ddql_optimal_execution.state.state method)": [[6, "ddql_optimal_execution.state.State.update_state"]], "statearray (class in ddql_optimal_execution.state)": [[7, "ddql_optimal_execution.state.StateArray"]], "__init__() (ddql_optimal_execution.state.statearray method)": [[7, "ddql_optimal_execution.state.StateArray.__init__"]], "append() (ddql_optimal_execution.state.statearray method)": [[7, "ddql_optimal_execution.state.StateArray.append"]], "astensor (ddql_optimal_execution.state.statearray property)": [[7, "ddql_optimal_execution.state.StateArray.astensor"]]}})